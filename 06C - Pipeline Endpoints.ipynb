{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versioning a Pipeline\n",
    "\n",
    "In the last two labs, you [created](labdocs/Lab06A.md) a pipeline and [published](labdocs/Lab06B.md) it as a service.  Now you're going to learn about versioning published pipeline.\n",
    "\n",
    "## Connect to Your Workspace\n",
    "\n",
    "The first thing you need to do is to connect to your workspace using the Azure ML SDK.\n",
    "\n",
    "> **Note**: If the authenticated session with your Azure subscription has expired since you completed the previous exercise, you'll be prompted to reauthenticate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Scripts for Pipeline Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = 'versioning'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $experiment_folder/train.py\n",
    "# Import libraries\n",
    "import argparse\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--some_parameter', type=str, dest='some_parameter', default=\"abc\", help='Some parameter value')\n",
    "    args = parser.parse_args()    \n",
    "\n",
    "    print(f\"Argument some_parameter: {args.some_parameter}\")\n",
    "    \n",
    "    print(\"Here we would train a model...\")\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a Compute Environment for the Pipeline Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"aml-cluster\"\n",
    "\n",
    "# Verify that cluster exists\n",
    "try:\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If not, create it\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS2_V2', max_nodes=2)\n",
    "    pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "pipeline_cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compose and Publish the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "step = PythonScriptStep(\n",
    "    name='training',\n",
    "    source_directory=experiment_folder,\n",
    "    script_name='train.py',\n",
    "    compute_target=pipeline_cluster,\n",
    "    runconfig=pipeline_run_config\n",
    ")\n",
    "\n",
    "pipeline_steps = [step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "pipeline.publish(name='Model training pipeline', description='', version='1')\n",
    "print(\"Pipeline published!\")\n",
    "\n",
    "experiment_name = 'model-training'\n",
    "experiment = Experiment(ws, name=experiment_name)\n",
    "experiment.submit(pipeline)\n",
    "print(\"Experiment submitted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publishing - a better way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify the pipeline run you want to publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineRun\n",
    "\n",
    "pipeline_experiment = ws.experiments.get(experiment_name)\n",
    "\n",
    "# get the latest completed or\n",
    "# pipeline_run = None\n",
    "# for run in pipeline_experiment.get_runs():\n",
    "#     if run.status == 'Completed':\n",
    "#         pipeline_run = run\n",
    "#         break\n",
    "# the specific one\n",
    "pipeline_run = PipelineRun(pipeline_experiment, run_id='17856a2c-0e35-442e-958c-7bdd0f203b26')\n",
    "print(pipeline_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a PipelineEndpoint and use it as a facade for published pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineEndpoint, PublishedPipeline\n",
    "\n",
    "pipeline_version = '2.0'\n",
    "pipeline_name_prefix = 'Model training pipeline'\n",
    "pipeline_name = f\"{pipeline_name_prefix} - version {pipeline_version}\"\n",
    "\n",
    "found_published_pipeline = None\n",
    "for published_pipeline in PublishedPipeline.list(ws):\n",
    "    if published_pipeline.name.startswith(pipeline_name_prefix) and published_pipeline.version == pipeline_version:\n",
    "        found_published_pipeline = published_pipeline\n",
    "        break\n",
    "\n",
    "if found_published_pipeline is not None:\n",
    "    print(\"Found the version, about to add the specified pipeline to pipeline endpoint...\")\n",
    "    print(found_published_pipeline)\n",
    "    \n",
    "    # publish a new edition of this pipeline version\n",
    "    newly_published_pipeline = pipeline.publish(\n",
    "        name=pipeline_name, \n",
    "        description=\"Trains model\",\n",
    "        version=pipeline_version) \n",
    "    # set a specified pipeline as a new available edition (preserving URL address)\n",
    "    pipeline_endpoint = PipelineEndpoint.get(workspace=ws, name=pipeline_name)\n",
    "    pipeline_endpoint.add_default(newly_published_pipeline)   \n",
    "\n",
    "else:\n",
    "    print(\"Not found, about to publish a new version...\")\n",
    "\n",
    "    # Publish pipeline \n",
    "    published_pipeline = pipeline_run.publish_pipeline(\n",
    "        name=pipeline_name, \n",
    "        description=\"Trains model\", \n",
    "        version=pipeline_version)\n",
    "    \n",
    "    pipeline_endpoint = PipelineEndpoint.publish(\n",
    "        workspace=ws, \n",
    "        name=pipeline_name, \n",
    "        description=\"Trains model\", \n",
    "        pipeline=published_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List all published pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for published_pipeline in PublishedPipeline.list(ws):\n",
    "    print(published_pipeline)\n",
    "    print(\"Version: \", published_pipeline.version)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List active Pipeline Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for endpoint in PipelineEndpoint.list(ws, active_only=False):\n",
    "    print(endpoint)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Pipeline Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print(\"Authentication header ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "rest_endpoint = f'https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/{subscription_id}/resourceGroups/{resource_group_name}/' + \\\n",
    "                'providers/Microsoft.MachineLearningServices/workspaces/AMLService/PipelineRuns/PipelineEndpointSubmit/Id/' + \\\n",
    "                'e1eeb9f3-827e-438f-beeb-4792d821bd4b'\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
